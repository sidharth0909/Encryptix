# Encryptix
Hello everyone my name is sidharth saholiya, i am currently pursuing Bachelor of engineering in IT (Currently in sem 7)
I am currency a Machine Learning intern at encryptix.so encryptix provide 4 month virtual internship, where you are given a set of project list with their corresponding dataset and the intern has to complete any 3 projects from it. This is a great opportunity to learn and understand new models and Algorithms.

This Repo will contain 3 Task

#1. Movie Genre Classification - This Projects lets you understand the basics of the Machine learning Project. It also explores important concepts such as Lancaster Stemmer, Text Vectorization Using TF-IDF, and the Naive bayes model
Structure of the Project:
1. Import the necessary Libraries
2. Load the Dataset
3. Perform some basic commands to understand the data. Eg. df.head(), df.info() and so on
4.Visualization and EDA
5. Data Preprocessing and Text Cleaning
6. Text Vectorization using TF-IDF
7. Splitting Data and Building Model
8. Prediction and Result

Necessary Definitions
1. TF-IDF: stands for Term Frequency Inverse Document Frequency of records. It can be defined as the calculation of how relevant a word in a series or corpus is to a text. 
2. Lancaster Stemmer: This initialises the Lancaster Stemmer, a tool used in natural language processing (NLP) to reduce words to their root form (e.g., "running" to "run"). This process is known as stemming.
3. stopwords.words('english'): This retrieves a list of common English stopwords from the NLTK library (like "the", "and", "is"), which are often removed from text during preprocessing because they don't carry significant meaning.

#2. Spam Sms Detection - This Project is about SMS-Spam-Detection, In this project i have used Naive Bayes model for prediction. 
Structure of the Project:
1. Import the necessary Libraries
2. Load the Dataset
3. Perform some basic commands to understand the data. Eg. df.head(), df.info() and so on
4. Visualization 
5. Data Preprocessing 
6. Label Encoder 
7. Splitting Data and Building Model
8. Prediction and Result

Apart from the basic stuff i had understood the following new topics from this project

1. NLTK - Natural Language Toolkit It is a platform for building Python programs to work with human language data for more click on this link - https://www.nltk.org/
2. Porter Stemmer - It applies a series of rules to remove common suffixes from English words.Example: "running" -> "run", "happier" -> "happi".
3. PUNKT - Punkt is a pre-trained model that helps in sentence segmentation and tokenization. Tokenization is the process of splitting text into individual words or sentences. for more - https://www.nltk.org/api/nltk.tokenize.punkt.html
4. wordcloud - Combines all the text documents into a single string. Uses WordCloud to generate and visualize the most frequent words.


#3. Credit card Fraud Detection - 


